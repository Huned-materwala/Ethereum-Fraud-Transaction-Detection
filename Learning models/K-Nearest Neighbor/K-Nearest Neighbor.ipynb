{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c930cd3-1eb6-41e3-a4db-8e84bbf529f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import ttest_rel\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551ccaf-8208-4d2f-941f-93cf011733c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "ETFD = pd.read_csv(r\"../../Dataset/ETFD_Dataset.txt\", sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049a26c-78d0-4acc-b86a-084b7406c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine dependent variables and class labels\n",
    "X = ETFD.drop('Fraud', axis=1)\n",
    "y = ETFD['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a49d1-e3a8-4d50-92fb-a731c72da8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom scoring function\n",
    "def custom_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    \n",
    "    # Calculate precision and recall with zero_division=0 to handle undefined cases\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Handle case where both precision and recall are zero\n",
    "    if precision == 0 and recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate the score\n",
    "    score = 1 / ((((1 - precision) ** 2) * fp + (1 - recall) * fn) + 1)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04100b7d-8070-40d4-bd12-19952601d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store results\n",
    "results = pd.DataFrame(columns=[\n",
    "    'Random State', \n",
    "    'Train Accuracy', 'Train Macro Precision', 'Train Macro Recall', 'Train Macro F1-Score', 'Train AUC',\n",
    "    'Test Accuracy', 'Test Macro Precision', 'Test Macro Recall', 'Test Macro F1-Score', 'Test AUC',\n",
    "    'Training Time', 'Validation Time', 'Tuning Time',\n",
    "    'TP Train', 'TN Train', 'FP Train', 'FN Train',\n",
    "    'TP Test', 'TN Test', 'FP Test', 'FN Test'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b91b9-e6a7-4e26-ac35-a0783a4f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over random states\n",
    "for random_state in range(1, 11):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    # Initialize KNN classifier\n",
    "    KNN = KNeighborsClassifier()\n",
    "    \n",
    "    # Define hyperparameters grid for tuning\n",
    "    param_grid = {\n",
    "        'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=KNN, param_grid=param_grid, n_jobs=-1, verbose=2, cv=10, scoring=make_scorer(custom_score))\n",
    "    \n",
    "    # Start hyperparameter tuning time\n",
    "    start_tuning_time = time.time()\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # End hyperparameter tuning time\n",
    "    end_tuning_time = time.time()\n",
    "    \n",
    "    # Get best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Save best hyperparameters to a text file\n",
    "    with open(f'best_hyperparameters_{random_state}.txt', 'w') as f:\n",
    "        f.write(str(best_params))\n",
    "    \n",
    "    # Get tuning time\n",
    "    tuning_time = end_tuning_time - start_tuning_time\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_KNN = grid_search.best_estimator_\n",
    "    \n",
    "    # Save the best model\n",
    "    joblib.dump(best_KNN, f'best_model_random_state_{random_state}.joblib')\n",
    "    \n",
    "    # Start training time for the best model\n",
    "    start_training_time = time.time()\n",
    "    \n",
    "    # Train the model with the best parameters\n",
    "    best_KNN.fit(X_train, y_train)\n",
    "    \n",
    "    # End training time for the best model\n",
    "    end_training_time = time.time()\n",
    "    \n",
    "    # Get training time\n",
    "    training_time = end_training_time - start_training_time\n",
    "    \n",
    "    # Start validation time\n",
    "    start_validation_time = time.time()\n",
    "    \n",
    "    # Predict on training set\n",
    "    y_train_pred = best_KNN.predict(X_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_test_pred = best_KNN.predict(X_test)\n",
    "    \n",
    "    # End validation time\n",
    "    end_validation_time = time.time()\n",
    "    \n",
    "    # Get validation time\n",
    "    validation_time = end_validation_time - start_validation_time\n",
    "\n",
    "    # Calculate TP, TN, FP, FN for training set\n",
    "    tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN for test set\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    \n",
    "    # Calculate training set evaluation metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='macro')\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='macro')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Calculate test set evaluation metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Create a new row for the results\n",
    "    new_row = {\n",
    "        'Random State': random_state,\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Train Macro Precision': train_precision,\n",
    "        'Train Macro Recall': train_recall,\n",
    "        'Train Macro F1-Score': train_f1,\n",
    "        'Train AUC': train_auc,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Macro Precision': test_precision,\n",
    "        'Test Macro Recall': test_recall,\n",
    "        'Test Macro F1-Score': test_f1,\n",
    "        'Test AUC': test_auc,\n",
    "        'Training Time': training_time,\n",
    "        'Validation Time': validation_time,\n",
    "        'Tuning Time': tuning_time,\n",
    "        'TP Train': tp_train,\n",
    "        'TN Train': tn_train,\n",
    "        'FP Train': fp_train,\n",
    "        'FN Train': fn_train,\n",
    "        'TP Test': tp_test,\n",
    "        'TN Test': tn_test,\n",
    "        'FP Test': fp_test,\n",
    "        'FN Test': fn_test\n",
    "    }\n",
    "    \n",
    "    # Append the new row to the DataFrame using pd.concat\n",
    "    results = pd.concat([results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Save results to CSV file\n",
    "results.to_csv('ETFD_KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31cf517-9abc-458e-b219-99b2a5732ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
